apiVersion: v1
kind: ConfigMap
metadata:
  name: templates
data:
  snapshot.yaml: |
    apiVersion: snapshot.storage.k8s.io/v1
    kind: VolumeSnapshot
    metadata:
      name: ${app}-${type}-${freq}-${id}
    spec:
      volumeSnapshotClassName: ${vsc}
      source:
        persistentVolumeClaimName: ${pvc}
  recover.yaml: |
    kind: PersistentVolumeClaim
    apiVersion: v1
    metadata:
      name: ${app}-${type}-pvc-last
    spec:
      accessModes:
        - ReadWriteOnce
      resources:
        requests:
          storage: 1Gi
      storageClassName: ${sc}
      volumeMode: Filesystem
      dataSource:
        apiGroup: snapshot.storage.k8s.io
        kind: VolumeSnapshot
        name: ${app}-${type}-${freq}-${id}
  daily.sh: |
    PVC=`kubectl get deployment/${app}-${type} -o custom-columns=PVC:.spec.template.spec.volumes[].persistentVolumeClaim.claimName | tail -1`
    ID=`date +'%s000'`
    sed -e "s/\${id}/$ID/g" -e "s/\${pvc}/$PVC/g" -e "s/\${freq}/daily/g" /var/configmap/snapshot.yaml > /tmp/snapshot.yaml
    kubectl apply -f /tmp/snapshot.yaml
    kubectl get volumesnapshot -o custom-columns=NAME:.metadata.name --sort-by='{.metadata.name}' | grep "^${app}-${type}-daily-" | tac | awk '{if (NR>2) system("kubectl delete volumesnapshot/"$1);}'
  hourly.sh: |
    PVC=`kubectl get deployment/${app}-${type} -o custom-columns=PVC:.spec.template.spec.volumes[].persistentVolumeClaim.claimName | tail -1`
    kubectl delete pvc/${app}-${type}-pvc-last
    ID=`date +'%s000'`
    sed -e "s/\${id}/$ID/g" -e "s/\${pvc}/$PVC/g" -e "s/\${freq}/hourly/g" /var/configmap/snapshot.yaml > /tmp/snapshot.yaml
    kubectl apply -f /tmp/snapshot.yaml
    kubectl get volumesnapshot -o custom-columns=NAME:.metadata.name --sort-by='{.metadata.name}' | grep "^${app}-${type}-hourly-" | tac | awk '{if (NR>2) system("kubectl delete volumesnapshot/"$1);}'
    sed -e "s/\${id}/$ID/g" -e "s/\${freq}/hourly/g" /var/configmap/recover.yaml > /tmp/recover.yaml
    sleep 120
    kubectl apply -f /tmp/recover.yaml
  replication.sh: |
    aws s3 --endpoint-url https://s3-openshift-storage.apps.ocpk2.redhat.local/ --no-verify-ssl sync /var/data s3://${app}-${type}-s3/
---
apiVersion: objectbucket.io/v1alpha1
kind: ObjectBucketClaim
metadata:
  name: ${app}-${type}-s3 
spec:
  bucketName: ${app}-${type}-s3 
  storageClassName: openshift-storage.noobaa.io
---
apiVersion: batch/v1beta1
kind: CronJob
metadata:
  name: hourly-backup-${app}-${type}
spec:
  schedule: "0 * * * *"
  jobTemplate:
    spec:
      template:
        spec:
          restartPolicy: Never
          containers:
          - name: kubectl-aws
            image: expert360/kubectl-awscli:v1.11.2
            command: [ "sh", "/var/configmap/hourly.sh" ]
            volumeMounts:
              - mountPath: /var/configmap
                name: configtemplate
          volumes:
            - configMap:
                name: templates 
              name: configtemplate
---
apiVersion: batch/v1beta1
kind: CronJob
metadata:
  name: daily-backup-${app}-${type}
spec:
  schedule: "0 0 * * *"
  jobTemplate:
    spec:
      template:
        spec:
          restartPolicy: Never
          containers:
          - name: kubectl-aws
            image: expert360/kubectl-awscli:v1.11.2
            command: [ "sh", "/var/configmap/daily.sh" ]
            volumeMounts:
              - mountPath: /var/configmap
                name: configtemplate
          volumes:
            - configMap:
                name: templates
              name: configtemplate
---
apiVersion: batch/v1beta1
kind: CronJob
metadata:
  name: hourly-replication-${app}-${type}
spec:
  schedule: "5 * * * *"
  jobTemplate:
    spec:
      template:
        spec:
          restartPolicy: Never
          containers:
          - name: kubectl-aws
            image: expert360/kubectl-awscli:v1.11.2
            command: [ "sh", "/var/configmap/replication.sh" ]
            env:
              - name: AWS_ACCESS_KEY_ID 
                valueFrom:
                  secretKeyRef:
                    name: ${app}-${type}-s3 
                    key: AWS_ACCESS_KEY_ID 
              - name: AWS_SECRET_ACCESS_KEY 
                valueFrom:
                  secretKeyRef:
                    name: ${app}-${type}-s3
                    key: AWS_SECRET_ACCESS_KEY 
            volumeMounts:
              - mountPath: /var/configmap
                name: configtemplate
              - mountPath: /var/data
                name: ${type}-data
          volumes:
            - configMap:
                name: templates
              name: configtemplate
            - name: ${type}-data
              persistentVolumeClaim:
                claimName: ${app}-${type}-pvc-last


